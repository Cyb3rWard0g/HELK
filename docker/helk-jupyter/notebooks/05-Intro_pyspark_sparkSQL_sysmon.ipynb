{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduction to Elasticsearch and Spark SQL via Pyspark**\n",
    "----------------------------------------------------------------------------\n",
    "## Goals:\n",
    "* Practice Spark SQL via PySpark skills\n",
    "* Ensure JupyterLab Server, Spark Cluster & Elasticsearch are communicating\n",
    "* Learn to read from HELK elasticsearch indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import SparkSession Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a SparkSession instance\n",
    "* Define a **spark** variable\n",
    "* Pass values to the **appName** and **master** functions\n",
    "    * For the master function, we are going to use the HELK's Spark Master container (helk-spark-master)\n",
    "* This time add the **config()** function to set Elasticsearch information needed to read from it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**config(key=None, value=None, conf=None)**](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.SparkSession.Builder.config)\n",
    "* Sets a config option.\n",
    "* Options set using this method are automatically propagated to both SparkConf and SparkSession’s own configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"HELK Reader\") \\\n",
    "    .master(\"spark://helk-spark-master:7077\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the SparkSession variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://fbc1eb970956:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://helk-spark-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>HELK Reader</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7efed9725080>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from the HELK Elasticsearch via Spark SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Dataframe API to access Elasticsearch index (Elasticsearch-Sysmon Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As we know, Spark SQL is a Spark module for structured data processing, and provides a programming abstraction called DataFrames and can also act as distributed SQL query engine.\n",
    "* Elasticsearch becomes a native source for Spark SQL so that data can be indexed and queried from Spark SQL transparently\n",
    "* Spark SQL works with structured data - in other words, all entries are expected to have the same structure (same number of fields, of the same type and name)\n",
    "* Using unstructured data (documents with different structures) is not supported and will cause problems.\n",
    "* Through the **org.elasticsearch.spark.sql** package, esDF methods are available on the SQLContext API\n",
    "\n",
    "Reference: https://www.elastic.co/guide/en/elasticsearch/hadoop/current/spark.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_reader = (spark.read\n",
    "    .format(\"org.elasticsearch.spark.sql\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .option(\"es.read.field.as.array.include\", \"tags\")\n",
    "    .option(\"es.nodes\",\"helk-elasticsearch:9200\")\n",
    "    .option(\"es.net.http.auth.user\",\"elastic\")\n",
    ")\n",
    "    #PLEASE REMEMBER!!!!\n",
    "    #If you are using elastic TRIAL license, then you need the es.net.http.auth.pass config option set\n",
    "    #Example: .option(\"es.net.http.auth.pass\",\"elasticpassword\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**load(path=None, format=None, schema=None, **options)**](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrameReader.load)\n",
    "* Loads data from a data source and returns it as a :class`DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 4 ms, total: 4 ms\n",
      "Wall time: 3.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sysmon_df = es_reader.load(\"logs-endpoint-winevent-sysmon-*/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter our the data to only show certain data fields and events with the action **\"processcreate\"** which is Sysmon Event ID 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "processcreate_df = sysmon_df.filter(sysmon_df.action == \"processcreate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can select a few columns from your dataframe with the **select** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "processcreate_df = processcreate_df.select(\"process_guid\",\"process_parent_name\",\"process_parent_command_line\",\"process_name\",\"process_command_line\",\"action\",\"@timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+---------------------------+--------------------+--------------------+-------------+--------------------+\n",
      "|        process_guid|process_parent_name|process_parent_command_line|        process_name|process_command_line|       action|          @timestamp|\n",
      "+--------------------+-------------------+---------------------------+--------------------+--------------------+-------------+--------------------+\n",
      "|aa6b4a20-7cd9-5ce...|        svchost.exe|       c:\\windows\\system...|backgroundtaskhos...|\"c:\\windows\\syste...|processcreate|2019-05-18 21:44:...|\n",
      "|aa6b4a20-7cdf-5ce...|     powershell.exe|       c:\\windows\\system...|         conhost.exe|\\??\\c:\\windows\\sy...|processcreate|2019-05-18 21:45:...|\n",
      "|aa6b4a20-7d15-5ce...|        svchost.exe|       c:\\windows\\system...|backgroundtaskhos...|\"c:\\windows\\syste...|processcreate|2019-05-18 21:45:...|\n",
      "|aa6b4a20-7d16-5ce...|        svchost.exe|       c:\\windows\\system...|   runtimebroker.exe|c:\\windows\\system...|processcreate|2019-05-18 21:45:...|\n",
      "|03ba39f5-7d20-5ce...|        svchost.exe|       c:\\windows\\system...|        gpupdate.exe|gpupdate.exe /tar...|processcreate|2019-05-18 21:46:...|\n",
      "|03ba39f5-7d20-5ce...|       gpupdate.exe|       gpupdate.exe /tar...|         conhost.exe|\\??\\c:\\windows\\sy...|processcreate|2019-05-18 21:46:...|\n",
      "|03ba39f5-7d20-5ce...|       services.exe|       c:\\windows\\system...|         svchost.exe|c:\\windows\\system...|processcreate|2019-05-18 21:46:...|\n",
      "|aa6b4a20-7ce9-5ce...|        svchost.exe|       c:\\windows\\system...|       taskhostw.exe|taskhostw.exe key...|processcreate|2019-05-18 21:45:...|\n",
      "|aa6b4a20-7cea-5ce...|        svchost.exe|       c:\\windows\\system...|         dllhost.exe|c:\\windows\\system...|processcreate|2019-05-18 21:45:...|\n",
      "|aa6b4a20-7cea-5ce...|        svchost.exe|       c:\\windows\\system...|       taskhostw.exe|       taskhostw.exe|processcreate|2019-05-18 21:45:...|\n",
      "+--------------------+-------------------+---------------------------+--------------------+--------------------+-------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "CPU times: user 0 ns, sys: 4 ms, total: 4 ms\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "processcreate_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframes from the original Sysmon Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Filter the original **sysmon_df** dataframe\n",
    "* Select specific columns\n",
    "* display results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NetworkConnect Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the network events logged by Sysmon (Event ID 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "networkconnect_df = sysmon_df.filter(sysmon_df.action == \"networkconnect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "networkconnect_df = networkconnect_df.select(\"process_guid\",\"dst_ip_addr\",\"dst_port\",\"dst_host_name\",\"action\",\"@timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+-------------+--------+-------------+--------------+-----------------------+\n",
      "|process_guid                        |dst_ip_addr  |dst_port|dst_host_name|action        |@timestamp             |\n",
      "+------------------------------------+-------------+--------+-------------+--------------+-----------------------+\n",
      "|03ba39f5-50b2-5ce0-0000-00109995c501|10.0.10.106  |443     |null         |networkconnect|2019-05-18 21:44:43.063|\n",
      "|aa6b4a20-7b8d-5ce0-0000-001028031c00|10.0.10.106  |443     |null         |networkconnect|2019-05-18 21:44:51.333|\n",
      "|905CC552-2045-5CC5-0000-00105B2A0100|172.18.39.102|5985    |null         |networkconnect|2019-05-18 21:44:53.257|\n",
      "|03ba39f5-652c-5ce0-0000-0010760bff01|10.0.10.106  |443     |null         |networkconnect|2019-05-18 21:44:53.484|\n",
      "|03ba39f5-6e79-5ce0-0000-001032d21002|10.0.10.106  |443     |null         |networkconnect|2019-05-18 21:44:58.094|\n",
      "|03ba39f5-50b2-5ce0-0000-00109995c501|10.0.10.106  |443     |null         |networkconnect|2019-05-18 21:44:58.609|\n",
      "|03ba39f5-652c-5ce0-0000-0010760bff01|10.0.10.106  |443     |null         |networkconnect|2019-05-18 21:44:58.609|\n",
      "|03ba39f5-ea63-5ccb-0000-001050e60000|172.18.39.105|135     |it001        |networkconnect|2019-05-18 21:45:03.297|\n",
      "|03ba39f5-6e79-5ce0-0000-001032d21002|10.0.10.106  |443     |null         |networkconnect|2019-05-18 21:45:03.562|\n",
      "|03ba39f5-652c-5ce0-0000-0010760bff01|10.0.10.106  |443     |null         |networkconnect|2019-05-18 21:45:03.812|\n",
      "+------------------------------------+-------------+--------+-------------+--------------+-----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "networkconnect_df.show(10,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FileCreate Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filecreate_df = sysmon_df.filter(sysmon_df.action == \"filecreate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filecreate_df = filecreate_df.select(\"process_guid\",\"file_name\",\"action\",\"@timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+----------------------------------------------------------------------------------------------+----------+-----------------------+\n",
      "|process_guid                        |file_name                                                                                     |action    |@timestamp             |\n",
      "+------------------------------------+----------------------------------------------------------------------------------------------+----------+-----------------------+\n",
      "|aa6b4a20-7cde-5ce0-0000-00109ea71e00|c:\\users\\pgustavo\\appdata\\local\\temp\\__psscriptpolicytest_kld4kxox.voz.ps1                    |filecreate|2019-05-18 21:45:04.958|\n",
      "|aa6b4a20-7cde-5ce0-0000-00109ea71e00|c:\\users\\pgustavo\\appdata\\local\\temp\\__psscriptpolicytest_4ksn3cia.csg.psm1                   |filecreate|2019-05-18 21:45:04.958|\n",
      "|905CC552-2042-5CC5-0000-00103D150100|c:\\windows\\serviceprofiles\\localservice\\appdata\\local\\lastalive1.dat                          |filecreate|2019-05-18 21:45:11.649|\n",
      "|aa6b4a20-7719-5ce0-0000-001068a30000|c:\\windows\\temp\\his33a6.tmp                                                                   |filecreate|2019-05-18 21:45:11.796|\n",
      "|aa6b4a20-7735-5ce0-0000-001033f10100|c:\\windows\\system32\\sleepstudy\\screenon\\screenonpowerstudytracesession-2019-05-18-17-45-11.etl|filecreate|2019-05-18 21:45:11.99 |\n",
      "|aa6b4a20-7719-5ce0-0000-001068a30000|c:\\windows\\temp\\hisf7a6.tmp                                                                   |filecreate|2019-05-18 21:44:56.433|\n",
      "|aa6b4a20-7cde-5ce0-0000-00109ea71e00|c:\\users\\pgustavo\\documents\\20190518\\powershell_transcript.it001.rhzmf_up.20190518174505.txt  |filecreate|2019-05-18 21:45:05.573|\n",
      "|aa6b4a20-771f-5ce0-0000-00108a420100|c:\\windows\\prefetch\\powershell.exe-920bba2a.pf                                                |filecreate|2019-05-18 21:45:15.754|\n",
      "|aa6b4a20-771f-5ce0-0000-00108a420100|c:\\windows\\prefetch\\dllhost.exe-d8e67ed6.pf                                                   |filecreate|2019-05-18 21:45:26.147|\n",
      "|aa6b4a20-771f-5ce0-0000-00108a420100|c:\\windows\\prefetch\\wmiprvse.exe-1628051c.pf                                                  |filecreate|2019-05-18 21:45:15.648|\n",
      "+------------------------------------+----------------------------------------------------------------------------------------------+----------+-----------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 507 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filecreate_df.show(10,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark SQL JOINs & Sysmon Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**join(other, on=None, how=None)**](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.join)\n",
    "\n",
    "Joins with another DataFrame, using the given join expression.\n",
    "\n",
    "Parameters:\t\n",
    "* **other** – Right side of the join\n",
    "* **on** – a string for the join column name, a list of column names, a join expression (Column), or a list of Columns. If on is a string or a list of strings indicating the name of the join column(s), the column(s) must exist on both sides, and this performs an equi-join.\n",
    "* **how** – str, default inner. Must be one of: inner, cross, outer, full, full_outer, left, left_outer, right, right_outer, left_semi, and left_anti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ProcessCreate -> NetworkCreate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_network_df = processcreate_df.join(networkconnect_df, \"process_guid\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+--------------+\n",
      "|process_parent_name|process_name       |dst_ip_addr   |\n",
      "+-------------------+-------------------+--------------+\n",
      "|svchost.exe        |microsoftedgecp.exe|13.107.21.200 |\n",
      "|svchost.exe        |microsoftedgecp.exe|13.107.21.200 |\n",
      "|svchost.exe        |microsoftedgecp.exe|204.79.197.200|\n",
      "|svchost.exe        |microsoftedgecp.exe|72.30.2.182   |\n",
      "|svchost.exe        |microsoftedgecp.exe|204.79.197.203|\n",
      "|svchost.exe        |microsoftedgecp.exe|23.50.228.129 |\n",
      "|svchost.exe        |microsoftedgecp.exe|23.194.130.152|\n",
      "|svchost.exe        |microsoftedgecp.exe|23.194.130.145|\n",
      "|wmiprvse.exe       |powershell.exe     |10.0.10.106   |\n",
      "|wmiprvse.exe       |powershell.exe     |10.0.10.106   |\n",
      "|wmiprvse.exe       |powershell.exe     |10.0.10.106   |\n",
      "|wmiprvse.exe       |powershell.exe     |10.0.10.106   |\n",
      "|wmiprvse.exe       |powershell.exe     |10.0.10.106   |\n",
      "|wmiprvse.exe       |powershell.exe     |10.0.10.106   |\n",
      "|wmiprvse.exe       |powershell.exe     |10.0.10.106   |\n",
      "|wmiprvse.exe       |powershell.exe     |10.0.10.106   |\n",
      "|wmiprvse.exe       |powershell.exe     |10.0.10.106   |\n",
      "|wmiprvse.exe       |powershell.exe     |10.0.10.106   |\n",
      "|wmiprvse.exe       |powershell.exe     |10.0.10.106   |\n",
      "|wmiprvse.exe       |powershell.exe     |10.0.10.106   |\n",
      "+-------------------+-------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 5.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "process_network_df.select(\"process_parent_name\",\"process_name\",\"dst_ip_addr\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|process_parent_name|count|\n",
      "+-------------------+-----+\n",
      "|        wscript.exe|   49|\n",
      "|       wmiprvse.exe|   25|\n",
      "|        svchost.exe|    9|\n",
      "|       services.exe|    2|\n",
      "+-------------------+-----+\n",
      "\n",
      "CPU times: user 32 ms, sys: 80 ms, total: 112 ms\n",
      "Wall time: 18.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "process_network_df.groupBy('process_parent_name').count().sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------+-------------------+--------------+\n",
      "|process_parent_command_line                     |process_name       |dst_ip_addr   |\n",
      "+------------------------------------------------+-------------------+--------------+\n",
      "|c:\\windows\\system32\\svchost.exe -k dcomlaunch -p|microsoftedgecp.exe|13.107.21.200 |\n",
      "|c:\\windows\\system32\\svchost.exe -k dcomlaunch -p|microsoftedgecp.exe|13.107.21.200 |\n",
      "|c:\\windows\\system32\\svchost.exe -k dcomlaunch -p|microsoftedgecp.exe|204.79.197.200|\n",
      "|c:\\windows\\system32\\svchost.exe -k dcomlaunch -p|microsoftedgecp.exe|72.30.2.182   |\n",
      "|c:\\windows\\system32\\svchost.exe -k dcomlaunch -p|microsoftedgecp.exe|204.79.197.203|\n",
      "+------------------------------------------------+-------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 12 ms, sys: 32 ms, total: 44 ms\n",
      "Wall time: 14.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "(process_network_df\n",
    "            .filter(process_network_df\n",
    "            .process_parent_name==\"svchost.exe\")\n",
    "            .select(\"process_parent_command_line\",\"process_name\",\"dst_ip_addr\")\n",
    "            .show(5,truncate=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ProcessCreate -> FileCreate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's focus now on the least frequent events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_file_df = processcreate_df.join(filecreate_df, \"process_guid\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|process_parent_name|count|\n",
      "+-------------------+-----+\n",
      "|       wmiprvse.exe|    3|\n",
      "|        wscript.exe|    4|\n",
      "|        svchost.exe|    5|\n",
      "+-------------------+-----+\n",
      "\n",
      "CPU times: user 0 ns, sys: 220 ms, total: 220 ms\n",
      "Wall time: 24.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "process_file_df.groupBy('process_parent_name').count().sort('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark_Python3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
